{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries\n",
    "\n",
    "* Import necessary libraries for data manipulation, preprocessing, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/guyparsadanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/guyparsadanov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/guyparsadanov/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Download necessary NLTK resources (only run once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the Dataset\n",
    "\n",
    "* Load the dataset into a DataFrame. Ensure the data has two columns: label (0 for fake, 1 for true) and text (news content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  donald trump sends out embarrassing new year‚s...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚s name ...\n",
      "4      0  pope francis just called out donald trump duri...\n"
     ]
    }
   ],
   "source": [
    "# Define the file path and column names\n",
    "file_path = '/Users/guyparsadanov/Downloads/Iron-Hack-Work/W4/project-3-nlp/training_data_lowercase copy.csv'  # Replace with your file path\n",
    "column_names = ['label', 'text']\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, sep='\\t', header=None, names=column_names)\n",
    "\n",
    "# Convert labels to integers (just in case they aren't)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Text Preprocessing\n",
    "\n",
    "* This step cleans the text by removing punctuation, numbers, and stopwords. It also applies lemmatization to reduce words to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  donald trump sends out embarrassing new year‚s...   \n",
      "1  drunk bragging trump staffer started russian c...   \n",
      "2  sheriff david clarke becomes an internet joke ...   \n",
      "3  trump is so obsessed he even has obama‚s name ...   \n",
      "4  pope francis just called out donald trump duri...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  donald trump sends embarrassing new year‚s eve...  \n",
      "1  drunk bragging trump staffer started russian c...  \n",
      "2  sheriff david clarke becomes internet joke thr...  \n",
      "3  trump obsessed even obama‚s name coded website...  \n",
      "4  pope francis called donald trump christmas speech  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \" \", text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    # text = re.sub(r'^[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "    # Substitute multiple spaces with a single space\n",
    "    # text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove all special characters\n",
    "    # text = re.sub(r'[^a-zA-Z\\s]', ' ', text)  # Keep only letters and spaces\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    # text = text.lower()\n",
    "    \n",
    "    # Tokenize and remove stopwords, then lemmatize\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "print(df[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split the Data into Training and Testing Sets\n",
    "\n",
    "* Divide the data into training and testing sets (80% train, 20% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (cleaned text) and labels\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Vectorize Text Using BoW and TF-IDF\n",
    "\n",
    "* Transform the text data into numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words (BoW) Vectorization\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train and Evaluate Classifiers\n",
    "\n",
    "* Train Logistic Regression and Multinomial Naive Bayes models and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression (BoW):\n",
      "\n",
      "Accuracy: 0.9387\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      3529\n",
      "           1       0.93      0.95      0.94      3302\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3289  240]\n",
      " [ 179 3123]]\n",
      "------------------------------------------------------------\n",
      "Results for Logistic Regression (TF-IDF):\n",
      "\n",
      "Accuracy: 0.9353\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3529\n",
      "           1       0.93      0.94      0.93      3302\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3282  247]\n",
      " [ 195 3107]]\n",
      "------------------------------------------------------------\n",
      "Results for Multinomial Naive Bayes (BoW):\n",
      "\n",
      "Accuracy: 0.9365\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3529\n",
      "           1       0.94      0.93      0.93      3302\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3321  208]\n",
      " [ 226 3076]]\n",
      "------------------------------------------------------------\n",
      "Results for Multinomial Naive Bayes (TF-IDF):\n",
      "\n",
      "Accuracy: 0.9344\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      3529\n",
      "           1       0.94      0.93      0.93      3302\n",
      "\n",
      "    accuracy                           0.93      6831\n",
      "   macro avg       0.93      0.93      0.93      6831\n",
      "weighted avg       0.93      0.93      0.93      6831\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3319  210]\n",
      " [ 238 3064]]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print accuracy and classification report\n",
    "    print(f\"Results for {model_name}:\\n\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Logistic Regression with BoW\n",
    "log_reg_bow = LogisticRegression()\n",
    "train_and_evaluate(log_reg_bow, X_train_bow, X_test_bow, y_train, y_test, \"Logistic Regression (BoW)\")\n",
    "\n",
    "# Logistic Regression with TF-IDF\n",
    "log_reg_tfidf = LogisticRegression()\n",
    "train_and_evaluate(log_reg_tfidf, X_train_tfidf, X_test_tfidf, y_train, y_test, \"Logistic Regression (TF-IDF)\")\n",
    "\n",
    "# Multinomial Naive Bayes with BoW\n",
    "nb_bow = MultinomialNB()\n",
    "train_and_evaluate(nb_bow, X_train_bow, X_test_bow, y_train, y_test, \"Multinomial Naive Bayes (BoW)\")\n",
    "\n",
    "# Multinomial Naive Bayes with TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "train_and_evaluate(nb_tfidf, X_train_tfidf, X_test_tfidf, y_train, y_test, \"Multinomial Naive Bayes (TF-IDF)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
